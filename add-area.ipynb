{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c48c7d8-f1b9-429d-9332-7c428997ec7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add-area.ipynb            calles_bsas_fixed.geojson \u001b[34mto_add\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0602ac8f-18a6-4d0f-b649-d78071d533f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LOAD] calles_bsas_fixed.geojson (87.4MB)\n",
      "  -> features: 233,016\n",
      "\n",
      "[SCAN] to_add/ -> 3 file(s)\n",
      "  - to_add/export-2.geojson\n",
      "  - to_add/export-3.geojson\n",
      "  - to_add/export.geojson\n",
      "\n",
      "[FILTER] keeping only street line features (LineString/MultiLineString), excluding service/alley...\n",
      "  Base kept: 209,377 / 233,016\n",
      "\n",
      "[MERGE] base -> add_files\n",
      "    BASE: processed 50,000/233,016 (kept 49,091, dup 0, drop 909)\n",
      "    BASE: processed 100,000/233,016 (kept 95,979, dup 0, drop 4,021)\n",
      "    BASE: processed 150,000/233,016 (kept 139,837, dup 0, drop 10,163)\n",
      "    BASE: processed 200,000/233,016 (kept 183,445, dup 0, drop 16,555)\n",
      "  BASE: kept 209,377, dup 0, dropped 23,639\n",
      "\n",
      "[LOAD] to_add/export-2.geojson (17.1MB)\n",
      "  -> features: 21,373\n",
      "  export-2.geojson: kept 11,875, dup 9,471, dropped 27\n",
      "\n",
      "[LOAD] to_add/export-3.geojson (9.3MB)\n",
      "  -> features: 10,975\n",
      "  export-3.geojson: kept 3,810, dup 7,162, dropped 3\n",
      "\n",
      "[LOAD] to_add/export.geojson (21.6MB)\n",
      "  -> features: 26,403\n",
      "  export.geojson: kept 17,551, dup 8,833, dropped 19\n",
      "\n",
      "[BACKUP] saving -> calles_bsas_fixed.bak.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/37/ff6b_ykd6j9dvf5x0nggymx40000gn/T/ipykernel_79275/988550673.py:154: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  \"timestamp\": datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\",\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BACKUP] done (80.3MB)\n",
      "\n",
      "[WRITE] writing compact GeoJSON -> calles_bsas_fixed.geojson.tmp\n",
      "[WRITE] overwrite done -> calles_bsas_fixed.geojson (85.4MB)\n",
      "\n",
      "✅ Done.\n"
     ]
    }
   ],
   "source": [
    "#para ver areas de cobertura usar el boton cobertus de la version local del app cargar el shapefile en jupyter es imposible\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "\n",
    "BASE_FILE = \"calles_bsas_fixed.geojson\"\n",
    "TO_ADD_DIR = \"to_add\"\n",
    "BACKUP = True\n",
    "\n",
    "EXCLUDE_HIGHWAYS = {\"service\"}\n",
    "EXCLUDE_SERVICE_SUBTYPES = {\"alley\"}  # only relevant when highway=service\n",
    "\n",
    "KEEP_GEOMS = {\"LineString\", \"MultiLineString\"}  # keep streets as lines only\n",
    "\n",
    "def human_bytes(n: int) -> str:\n",
    "    for unit in [\"B\",\"KB\",\"MB\",\"GB\",\"TB\"]:\n",
    "        if n < 1024:\n",
    "            return f\"{n:.1f}{unit}\" if unit != \"B\" else f\"{n}{unit}\"\n",
    "        n /= 1024\n",
    "    return f\"{n:.1f}PB\"\n",
    "\n",
    "def load_feature_collection(path: str) -> dict:\n",
    "    print(f\"\\n[LOAD] {path} ({human_bytes(os.path.getsize(path))})\")\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    if not isinstance(data, dict) or data.get(\"type\") != \"FeatureCollection\":\n",
    "        raise ValueError(f\"{path} is not a GeoJSON FeatureCollection\")\n",
    "    feats = data.get(\"features\")\n",
    "    if not isinstance(feats, list):\n",
    "        raise ValueError(f\"{path} FeatureCollection has no features[] list\")\n",
    "    print(f\"  -> features: {len(feats):,}\")\n",
    "    return data\n",
    "\n",
    "def is_good_street_feature(feat: dict) -> bool:\n",
    "    if not isinstance(feat, dict) or feat.get(\"type\") != \"Feature\":\n",
    "        return False\n",
    "\n",
    "    geom = feat.get(\"geometry\") or {}\n",
    "    gtype = geom.get(\"type\")\n",
    "    if gtype not in KEEP_GEOMS:\n",
    "        return False\n",
    "\n",
    "    props = feat.get(\"properties\") or {}\n",
    "    hw = props.get(\"highway\")\n",
    "    if not hw:\n",
    "        return False\n",
    "\n",
    "    # exclude service roads entirely, and also alleys (usually service=alley)\n",
    "    if hw in EXCLUDE_HIGHWAYS:\n",
    "        service_val = props.get(\"service\")\n",
    "        if service_val in EXCLUDE_SERVICE_SUBTYPES or service_val is None:\n",
    "            return False\n",
    "\n",
    "    # Overpass sometimes includes pedestrian areas as polygons w/ area=yes; we already dropped polygons by geom type\n",
    "    return True\n",
    "\n",
    "def feature_key(feat: dict) -> str:\n",
    "    \"\"\"\n",
    "    Prefer stable OSM id when present; else hash geometry+key props.\n",
    "    This prevents duplicates without exploding file size.\n",
    "    \"\"\"\n",
    "    props = feat.get(\"properties\") or {}\n",
    "    osm_id = props.get(\"@id\") or props.get(\"id\")\n",
    "    if osm_id:\n",
    "        return f\"id:{osm_id}\"\n",
    "\n",
    "    # fallback: hash geom + highway + name\n",
    "    geom = feat.get(\"geometry\") or {}\n",
    "    payload = {\n",
    "        \"geometry\": geom,\n",
    "        \"highway\": props.get(\"highway\"),\n",
    "        \"name\": props.get(\"name\"),\n",
    "    }\n",
    "    s = json.dumps(payload, sort_keys=True, separators=(\",\", \":\"), ensure_ascii=False)\n",
    "    return \"h:\" + hashlib.sha1(s.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "def scan_to_add(dirpath: str) -> list[str]:\n",
    "    patterns = [os.path.join(dirpath, \"*.geojson\"), os.path.join(dirpath, \"*.json\")]\n",
    "    files = []\n",
    "    for p in patterns:\n",
    "        files.extend(glob.glob(p))\n",
    "    files = sorted(set(files))\n",
    "    print(f\"\\n[SCAN] {dirpath}/ -> {len(files)} file(s)\")\n",
    "    for f in files[:25]:\n",
    "        print(\"  -\", f)\n",
    "    if len(files) > 25:\n",
    "        print(f\"  ... (+{len(files)-25} more)\")\n",
    "    return files\n",
    "\n",
    "def write_compact_geojson(path: str, fc: dict) -> None:\n",
    "    tmp = path + \".tmp\"\n",
    "    print(f\"\\n[WRITE] writing compact GeoJSON -> {tmp}\")\n",
    "    with open(tmp, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(fc, f, ensure_ascii=False, separators=(\",\", \":\"))\n",
    "    os.replace(tmp, path)\n",
    "    print(f\"[WRITE] overwrite done -> {path} ({human_bytes(os.path.getsize(path))})\")\n",
    "\n",
    "def main():\n",
    "    if not os.path.exists(BASE_FILE):\n",
    "        raise FileNotFoundError(f\"Base file not found: {BASE_FILE}\")\n",
    "\n",
    "    base_fc = load_feature_collection(BASE_FILE)\n",
    "    base_feats = base_fc[\"features\"]\n",
    "\n",
    "    add_files = scan_to_add(TO_ADD_DIR)\n",
    "    if not add_files:\n",
    "        print(\"\\nNothing to add. Exiting.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n[FILTER] keeping only street line features (LineString/MultiLineString), excluding service/alley...\")\n",
    "    kept_before = sum(1 for _ in base_feats)\n",
    "    base_filtered = [f for f in base_feats if is_good_street_feature(f)]\n",
    "    print(f\"  Base kept: {len(base_filtered):,} / {kept_before:,}\")\n",
    "\n",
    "    # Dedup using keys\n",
    "    seen = set()\n",
    "    merged = []\n",
    "\n",
    "    def add_feats(feats: list, label: str):\n",
    "        nonlocal merged\n",
    "        total = len(feats)\n",
    "        kept = 0\n",
    "        dup = 0\n",
    "        bad = 0\n",
    "        for i, feat in enumerate(feats, 1):\n",
    "            if not is_good_street_feature(feat):\n",
    "                bad += 1\n",
    "                continue\n",
    "            k = feature_key(feat)\n",
    "            if k in seen:\n",
    "                dup += 1\n",
    "                continue\n",
    "            seen.add(k)\n",
    "            merged.append(feat)\n",
    "            kept += 1\n",
    "            if i % 50000 == 0:\n",
    "                print(f\"    {label}: processed {i:,}/{total:,} (kept {kept:,}, dup {dup:,}, drop {bad:,})\")\n",
    "        print(f\"  {label}: kept {kept:,}, dup {dup:,}, dropped {bad:,}\")\n",
    "\n",
    "    print(\"\\n[MERGE] base -> add_files\")\n",
    "    add_feats(base_feats, \"BASE\")\n",
    "\n",
    "    for fpath in add_files:\n",
    "        fc = load_feature_collection(fpath)\n",
    "        add_feats(fc[\"features\"], os.path.basename(fpath))\n",
    "\n",
    "    # Update metadata lightly\n",
    "    out_fc = {\n",
    "        \"type\": \"FeatureCollection\",\n",
    "        \"generator\": base_fc.get(\"generator\", \"merge_geojson_overpass.py\"),\n",
    "        \"timestamp\": datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\",\n",
    "        \"features\": merged,\n",
    "    }\n",
    "\n",
    "    # optional backup\n",
    "    if BACKUP:\n",
    "        backup_path = BASE_FILE.replace(\".geojson\", \"\") + \".bak.geojson\"\n",
    "        print(f\"\\n[BACKUP] saving -> {backup_path}\")\n",
    "        with open(backup_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(base_fc, f, ensure_ascii=False, separators=(\",\", \":\"))\n",
    "        print(f\"[BACKUP] done ({human_bytes(os.path.getsize(backup_path))})\")\n",
    "\n",
    "    write_compact_geojson(BASE_FILE, out_fc)\n",
    "    print(\"\\n✅ Done.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c64e4a5-382c-49f6-a878-927a0f6b5df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/main/Desktop/geojson-repo/bianca-geodata\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5c18bc-bc52-4f8c-8a23-c17434b85b61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
